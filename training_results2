HEADER: Date: 2020-04-24 10:02:04.103432  Learning Rate: 0.02  Epochs: 1
     Training with: ru_syntagrus-ud-test.conllu  and Testing with: ru_syntagrus-ud-dev.conllu
Epoch [1/1], Step [200/5879], Loss: 1.9415
Epoch [1/1], Step [400/5879], Loss: 3.1075
Epoch [1/1], Step [600/5879], Loss: 2.8756
Epoch [1/1], Step [800/5879], Loss: 2.5107
Epoch [1/1], Step [1000/5879], Loss: 3.1506
Epoch [1/1], Step [1200/5879], Loss: 2.5485
Epoch [1/1], Step [1400/5879], Loss: 2.6892
Epoch [1/1], Step [1600/5879], Loss: 4.1991
Epoch [1/1], Step [1800/5879], Loss: 2.6861
Epoch [1/1], Step [2000/5879], Loss: 2.4539
Epoch [1/1], Step [2200/5879], Loss: 2.8078
Epoch [1/1], Step [2400/5879], Loss: 2.6480
Epoch [1/1], Step [2600/5879], Loss: 2.4501
Epoch [1/1], Step [2800/5879], Loss: 3.8078
Epoch [1/1], Step [3000/5879], Loss: 2.8615
Epoch [1/1], Step [3200/5879], Loss: 3.6457
Epoch [1/1], Step [3400/5879], Loss: 3.1324
Epoch [1/1], Step [3600/5879], Loss: 3.3350
Epoch [1/1], Step [3800/5879], Loss: 2.6548
Epoch [1/1], Step [4000/5879], Loss: 3.0323
Epoch [1/1], Step [4200/5879], Loss: 2.4130
Epoch [1/1], Step [4400/5879], Loss: 2.9301
Epoch [1/1], Step [4600/5879], Loss: 2.9640
Epoch [1/1], Step [4800/5879], Loss: 4.5740
Epoch [1/1], Step [5000/5879], Loss: 2.4474
Epoch [1/1], Step [5200/5879], Loss: 3.2654
Epoch [1/1], Step [5400/5879], Loss: 2.7674
Epoch [1/1], Step [5600/5879], Loss: 3.6828
Epoch [1/1], Step [5800/5879], Loss: 3.2860
CONCLUSION: Date: 2020-04-24 10:02:04.103432  Learning Rate 0.02  Epochs: 1
Testing
Accuracy of the network:  7.399736396158915 %
HEADER: Date: 2020-04-24 10:52:46.040306  Learning Rate: 0.0001  Epochs: 1
     Training with: ru_syntagrus-ud-test.conllu  and Testing with: ru_syntagrus-ud-dev.conllu
Epoch [1/1], Step [200/5879], Loss: 3.0021
Epoch [1/1], Step [400/5879], Loss: 3.3611
Epoch [1/1], Step [600/5879], Loss: 3.0440
Epoch [1/1], Step [800/5879], Loss: 1.7066
Epoch [1/1], Step [1000/5879], Loss: 2.5621
Epoch [1/1], Step [1200/5879], Loss: 2.2283
Epoch [1/1], Step [1400/5879], Loss: 2.7322
Epoch [1/1], Step [1600/5879], Loss: 3.9765
Epoch [1/1], Step [1800/5879], Loss: 2.5426
Epoch [1/1], Step [2000/5879], Loss: 2.0429
Epoch [1/1], Step [2200/5879], Loss: 2.6622
Epoch [1/1], Step [2400/5879], Loss: 2.7811
Epoch [1/1], Step [2600/5879], Loss: 2.8921
Epoch [1/1], Step [2800/5879], Loss: 3.4926
Epoch [1/1], Step [3000/5879], Loss: 2.4495
Epoch [1/1], Step [3200/5879], Loss: 3.5221
Epoch [1/1], Step [3400/5879], Loss: 3.4039
Epoch [1/1], Step [3600/5879], Loss: 3.2908
Epoch [1/1], Step [3800/5879], Loss: 2.4048
Epoch [1/1], Step [4000/5879], Loss: 2.6478
Epoch [1/1], Step [4200/5879], Loss: 2.7457
Epoch [1/1], Step [4400/5879], Loss: 3.2507
Epoch [1/1], Step [4600/5879], Loss: 3.2770
Epoch [1/1], Step [4800/5879], Loss: 3.9208
Epoch [1/1], Step [5000/5879], Loss: 2.6178
Epoch [1/1], Step [5200/5879], Loss: 2.9026
Epoch [1/1], Step [5400/5879], Loss: 2.3216
Epoch [1/1], Step [5600/5879], Loss: 3.7873
Epoch [1/1], Step [5800/5879], Loss: 2.8245
CONCLUSION: Date: 2020-04-24 10:52:46.040306  Learning Rate 0.0001  Epochs: 1
Testing
Accuracy of the network:  12.31406514780644 %
HEADER: Date: 2020-05-01 02:14:55.598110  Learning Rate: 0.001  Epochs: 2
     Training with: ru_syntagrus-ud-train.conllu  and Testing with: ru_syntagrus-ud-dev.conllu
Epoch [1/2], Step [500/41793], Loss: 3.4145
Epoch [1/2], Step [1000/41793], Loss: 3.2531
Epoch [1/2], Step [1500/41793], Loss: 1.3634
Epoch [1/2], Step [2000/41793], Loss: 2.9576
Epoch [1/2], Step [2500/41793], Loss: 3.0573
Epoch [1/2], Step [3000/41793], Loss: 3.1863
Epoch [1/2], Step [3500/41793], Loss: 2.7955
Epoch [1/2], Step [4000/41793], Loss: 3.1063
Epoch [1/2], Step [4500/41793], Loss: 3.5493
Epoch [1/2], Step [5000/41793], Loss: 18.2824
Epoch [1/2], Step [5500/41793], Loss: 3.1364
Epoch [1/2], Step [6000/41793], Loss: 2.0554
Epoch [1/2], Step [6500/41793], Loss: 3.1212
Epoch [1/2], Step [7000/41793], Loss: 2.3432
Epoch [1/2], Step [7500/41793], Loss: 3.0066
Epoch [1/2], Step [8000/41793], Loss: 2.7992
Epoch [1/2], Step [8500/41793], Loss: 3.2038
Epoch [1/2], Step [9000/41793], Loss: 2.0284
Epoch [1/2], Step [9500/41793], Loss: 2.9066
Epoch [1/2], Step [10000/41793], Loss: 2.8311
Epoch [1/2], Step [10500/41793], Loss: 0.6065
Epoch [1/2], Step [11000/41793], Loss: 2.8988
Epoch [1/2], Step [11500/41793], Loss: 2.0430
Epoch [1/2], Step [12000/41793], Loss: 3.1906
Epoch [1/2], Step [12500/41793], Loss: 2.1859
Epoch [1/2], Step [13000/41793], Loss: 2.0371
Epoch [1/2], Step [13500/41793], Loss: 0.0022
Epoch [1/2], Step [14000/41793], Loss: 3.4276
Epoch [1/2], Step [14500/41793], Loss: 2.2973
Epoch [1/2], Step [15000/41793], Loss: 2.6953
Epoch [1/2], Step [15500/41793], Loss: 3.5391
Epoch [1/2], Step [16000/41793], Loss: 2.3226
Epoch [1/2], Step [16500/41793], Loss: 3.1740
Epoch [1/2], Step [17000/41793], Loss: 2.9537
Epoch [1/2], Step [17500/41793], Loss: 2.7205
Epoch [1/2], Step [18000/41793], Loss: 2.6453
Epoch [1/2], Step [18500/41793], Loss: 3.8852
Epoch [1/2], Step [19000/41793], Loss: 4.5232
Epoch [1/2], Step [19500/41793], Loss: 3.8337
Epoch [1/2], Step [20000/41793], Loss: 2.9101
Epoch [1/2], Step [20500/41793], Loss: 3.1491
Epoch [1/2], Step [21000/41793], Loss: 3.1948
Epoch [1/2], Step [21500/41793], Loss: 3.5163
Epoch [1/2], Step [22000/41793], Loss: 3.6047
Epoch [1/2], Step [22500/41793], Loss: 1.9483
Epoch [1/2], Step [23000/41793], Loss: 3.4684
Epoch [1/2], Step [23500/41793], Loss: 9.8611
Epoch [1/2], Step [24000/41793], Loss: 1.8427
Epoch [1/2], Step [24500/41793], Loss: 2.6143
Epoch [1/2], Step [25000/41793], Loss: 1.8210
Epoch [1/2], Step [25500/41793], Loss: 2.0058
Epoch [1/2], Step [26000/41793], Loss: 3.6288
Epoch [1/2], Step [26500/41793], Loss: 3.3243
Epoch [1/2], Step [27000/41793], Loss: 1.8280
Epoch [1/2], Step [27500/41793], Loss: 2.1486
Epoch [1/2], Step [28000/41793], Loss: 2.8197
Epoch [1/2], Step [28500/41793], Loss: 2.8597
Epoch [1/2], Step [29000/41793], Loss: 2.0357
Epoch [1/2], Step [29500/41793], Loss: 2.9545
Epoch [1/2], Step [30000/41793], Loss: 3.0663
Epoch [1/2], Step [30500/41793], Loss: 2.2474
Epoch [1/2], Step [31000/41793], Loss: 2.7843
Epoch [1/2], Step [31500/41793], Loss: 2.8257
Epoch [1/2], Step [32000/41793], Loss: 2.7209
Epoch [1/2], Step [32500/41793], Loss: 0.0003
Epoch [1/2], Step [33000/41793], Loss: 2.1405
Epoch [1/2], Step [33500/41793], Loss: 3.0945
Epoch [1/2], Step [34000/41793], Loss: 4.5444
Epoch [1/2], Step [34500/41793], Loss: 3.2361
Epoch [1/2], Step [35000/41793], Loss: 5.0066
Epoch [1/2], Step [35500/41793], Loss: 3.4700
Epoch [1/2], Step [36000/41793], Loss: 2.6988
Epoch [1/2], Step [36500/41793], Loss: 2.2645
Epoch [1/2], Step [37000/41793], Loss: 3.2069
Epoch [1/2], Step [37500/41793], Loss: 2.1971
Epoch [1/2], Step [38000/41793], Loss: 3.1533
Epoch [1/2], Step [38500/41793], Loss: 3.0584
Epoch [1/2], Step [39000/41793], Loss: 2.6212
Epoch [1/2], Step [39500/41793], Loss: 2.1073
Epoch [1/2], Step [40000/41793], Loss: 2.8333
Epoch [1/2], Step [40500/41793], Loss: 2.2791
Epoch [1/2], Step [41000/41793], Loss: 3.1494
Epoch [1/2], Step [41500/41793], Loss: 2.4914
Epoch [2/2], Step [500/41793], Loss: 1.6451
Epoch [2/2], Step [1000/41793], Loss: 2.3997
Epoch [2/2], Step [1500/41793], Loss: 0.0018
Epoch [2/2], Step [2000/41793], Loss: 2.9312
Epoch [2/2], Step [2500/41793], Loss: 2.9199
Epoch [2/2], Step [3000/41793], Loss: 3.1961
Epoch [2/2], Step [3500/41793], Loss: 2.5698
Epoch [2/2], Step [4000/41793], Loss: 2.2262
Epoch [2/2], Step [4500/41793], Loss: 3.0447
Epoch [2/2], Step [5000/41793], Loss: 30.9681
Epoch [2/2], Step [5500/41793], Loss: 3.1871
Epoch [2/2], Step [6000/41793], Loss: 2.8214
Epoch [2/2], Step [6500/41793], Loss: 3.1641
Epoch [2/2], Step [7000/41793], Loss: 2.9059
Epoch [2/2], Step [7500/41793], Loss: 3.1195
Epoch [2/2], Step [8000/41793], Loss: 2.9476
Epoch [2/2], Step [8500/41793], Loss: 3.2546
Epoch [2/2], Step [9000/41793], Loss: 2.0200
Epoch [2/2], Step [9500/41793], Loss: 3.1094
Epoch [2/2], Step [10000/41793], Loss: 3.1559
Epoch [2/2], Step [10500/41793], Loss: 0.9382
Epoch [2/2], Step [11000/41793], Loss: 3.1566
Epoch [2/2], Step [11500/41793], Loss: 1.9352
Epoch [2/2], Step [12000/41793], Loss: 3.4049
Epoch [2/2], Step [12500/41793], Loss: 2.7403
Epoch [2/2], Step [13000/41793], Loss: 1.7991
Epoch [2/2], Step [13500/41793], Loss: 0.0000
Epoch [2/2], Step [14000/41793], Loss: 3.3426
Epoch [2/2], Step [14500/41793], Loss: 2.0884
Epoch [2/2], Step [15000/41793], Loss: 2.6854
Epoch [2/2], Step [15500/41793], Loss: 3.2153
Epoch [2/2], Step [16000/41793], Loss: 2.1273
Epoch [2/2], Step [16500/41793], Loss: 3.3608
Epoch [2/2], Step [17000/41793], Loss: 3.0207
Epoch [2/2], Step [17500/41793], Loss: 2.7597
Epoch [2/2], Step [18000/41793], Loss: 2.5192
Epoch [2/2], Step [18500/41793], Loss: 5.0837
Epoch [2/2], Step [19000/41793], Loss: 3.2947
Epoch [2/2], Step [19500/41793], Loss: 4.6255
Epoch [2/2], Step [20000/41793], Loss: 2.4118
Epoch [2/2], Step [20500/41793], Loss: 3.2311
Epoch [2/2], Step [21000/41793], Loss: 3.1131
Epoch [2/2], Step [21500/41793], Loss: 3.3157
Epoch [2/2], Step [22000/41793], Loss: 3.9060
Epoch [2/2], Step [22500/41793], Loss: 1.9091
Epoch [2/2], Step [23000/41793], Loss: 3.5391
Epoch [2/2], Step [23500/41793], Loss: 4.3760
Epoch [2/2], Step [24000/41793], Loss: 2.4631
Epoch [2/2], Step [24500/41793], Loss: 2.8491
Epoch [2/2], Step [25000/41793], Loss: 1.3722
Epoch [2/2], Step [25500/41793], Loss: 2.7422
Epoch [2/2], Step [26000/41793], Loss: 3.0306
Epoch [2/2], Step [26500/41793], Loss: 3.5105
Epoch [2/2], Step [27000/41793], Loss: 2.9391
Epoch [2/2], Step [27500/41793], Loss: 2.0572
Epoch [2/2], Step [28000/41793], Loss: 2.5638
Epoch [2/2], Step [28500/41793], Loss: 3.0727
Epoch [2/2], Step [29000/41793], Loss: 2.6966
Epoch [2/2], Step [29500/41793], Loss: 3.0393
Epoch [2/2], Step [30000/41793], Loss: 2.3963
Epoch [2/2], Step [30500/41793], Loss: 1.8994
Epoch [2/2], Step [31000/41793], Loss: 2.9981
Epoch [2/2], Step [31500/41793], Loss: 3.2901
Epoch [2/2], Step [32000/41793], Loss: 2.7665
Epoch [2/2], Step [32500/41793], Loss: 0.0000
Epoch [2/2], Step [33000/41793], Loss: 2.3079
Epoch [2/2], Step [33500/41793], Loss: 3.0671
Epoch [2/2], Step [34000/41793], Loss: 2.7805
Epoch [2/2], Step [34500/41793], Loss: 3.1101
Epoch [2/2], Step [35000/41793], Loss: 3.9716
Epoch [2/2], Step [35500/41793], Loss: 3.6419
Epoch [2/2], Step [36000/41793], Loss: 3.4606
Epoch [2/2], Step [36500/41793], Loss: 1.3851
Epoch [2/2], Step [37000/41793], Loss: 3.2283
Epoch [2/2], Step [37500/41793], Loss: 1.9185
Epoch [2/2], Step [38000/41793], Loss: 2.9283
Epoch [2/2], Step [38500/41793], Loss: 3.5012
Epoch [2/2], Step [39000/41793], Loss: 2.3198
Epoch [2/2], Step [39500/41793], Loss: 2.2129
Epoch [2/2], Step [40000/41793], Loss: 2.9639
Epoch [2/2], Step [40500/41793], Loss: 3.1731
Epoch [2/2], Step [41000/41793], Loss: 3.0437
Epoch [2/2], Step [41500/41793], Loss: 3.0773
CONCLUSION: Date: 2020-05-01 02:14:55.598110  Learning Rate 0.001  Epochs: 2
Testing
Accuracy of the network:  13.763886273771417 %
